
# Localiza Data Engineering Case

## ğŸ“– IntroduÃ§Ã£o

Este projeto foi desenvolvido como parte do test case para a Localiza, com foco na criaÃ§Ã£o de pipelines de dados utilizando ferramentas de orquestraÃ§Ã£o e modelagem de dados.

Temas abordados:
- IngestÃ£o de arquivos CSV para transformaÃ§Ã£o e anÃ¡lise de dados.
- ExecuÃ§Ã£o de consultas SQL.
- ImplementaÃ§Ã£o de pipelines utilizando Airflow, Docker e DBT.

---

## ğŸ”§ Recursos Utilizados

- **Apache Airflow:** OrquestraÃ§Ã£o de workflows.
- **DBT:** TransformaÃ§Ãµes de dados SQL.
- **Docker:** ContainerizaÃ§Ã£o para garantir reprodutibilidade.
- **Postgres:** Armazenamento dos dados processados.

---

## ğŸš€ Passo a Passo de ExecuÃ§Ã£o

1. **Clone o repositÃ³rio:**  
   ```bash
   git clone <url_do_repositorio>
   ```

2. **Entre no diretÃ³rio do projeto:**  
   ```bash
   cd <nome_do_repositorio>
   ```
4. **Copie o arquivo csv do desafio para pasta:**  
   ```bash
   cp -r <endereco_atual_do_csv> csv/raw_fraud_credit.csv
   ```

3. **Suba os contÃªineres com Docker Compose:**  
   ```bash
   docker compose up -d
   ```

5. **Acesse o Airflow no navegador:**  
   [http://localhost:8080](http://localhost:8080)

6. **Observe as DAGs listadas e inicie conforme necessÃ¡rio.**  
   ![Imagem de exemplo](./readme-images/dags_implementadas.png)

---

## ğŸ” Desafios Propostos e SoluÃ§Ãµes

### Desafio 1: Ranking de regiÃµes por mÃ©dia de "Risk Score" e anÃ¡lise de transaÃ§Ãµes recentes

**DescriÃ§Ã£o do Desafio:**  
1. Implementar um pipeline que:  
   - Importe dados de um arquivo CSV.  
   - Realize a limpeza e carregamento em tabelas intermediÃ¡rias.  
   - Gere uma tabela-resultado com a mÃ©dia de "risk score" por regiÃ£o.  
   - Gere uma tabela-resultado listando os 3 maiores "receiving address" por "amount" considerando transaÃ§Ãµes mais recentes.

**SoluÃ§Ãµes Implementadas:**  
- **Modelos:**  
  - `myCosmosDbt/dags/dbt/localiza_dw/models/staging/credit_fraud`  
  - `myCosmosDbt/dags/dbt/localiza_dw/models/marts/credit_fraud`  

- **DAGs:**  
  - `myCosmosDbt/dags/dag_ingestion_daily-fraud_credit.py`  
  - `myCosmosDbt/dags/dag_dbt-model_fraud_credit.py`
- **DAG:**  
  - `DAG IngestÃ£o`
  ![dag](./readme-images/dag-fraud_credit-ingestion.png)
  - `DAG Modelagem`
  ![dag](./readme-images/dag-fraud_credit.png)

---

### Desafio 2: Consultas SQL para anÃ¡lise de vendedores

**DescriÃ§Ã£o do Desafio:**  
1. Esboce uma consulta SQL que:
   - Vendem quantidade de itens do produto de cÃ³digo PROD maior que a
mÃ©dia de vendas por vendedor do produto de cÃ³digo PROD em sua loja;

   - Vendem quantidade de itens do produto de cÃ³digo PROD maior que a
mÃ©dia de vendas por vendedor do produto de cÃ³digo PROD nas lojas com
mais de 1000 vendas do produto de cÃ³digo PROD no perÃ­odo; 

**SoluÃ§Ãµes Implementadas:**

Para soluÃ§Ã£o foi desenvolvido uma query dinamica, utilizando `vars` do DBT para passar os parametros de entrada.

- **Modelos:**  
  - `myCosmosDbt/dags/dbt/localiza_dw/models/marts/sales/ad_hoc_summary_vendas.sql`

- **DAGs:**  
  - `myCosmosDbt/dags/dag_dbt-model_sales.py`
- **Script DBT:**  
  - `SQL`
![sql](./readme-images/ad_hoc_summary_vendas.png)

2. Esboce uma consulta SQL que:  
   - Liste vendedores cujas vendas do produto PROD foram sempre crescentes no perÃ­odo especificado.

**SoluÃ§Ãµes Implementadas:**  
- **Modelos:**  
  - `myCosmosDbt/dags/dbt/localiza_dw/models/marts/sales/ad_hoc_sales_growth.sql`

- **DAGs:**  
  - `myCosmosDbt/dags/dag_dbt-model_sales.py`

- **Script DBT:**  
  - `SQL`
![sql](./readme-images/ad_hoc_sales_growth.png)

- **DAG:**  
  - `DAG Sales`
![sql](./readme-images/dag-model_sales.png)

---

## ğŸ›  Estrutura do Projeto

```
localiza_case/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ dag_dbt-model_sales.py
â”‚   â”œâ”€â”€ dag_dbt-model_fraud_credit.py
â”‚   â”œâ”€â”€ dag_ingestion_daily-credit_fraud.py
â”‚   â”œâ”€â”€ dbt/
â”‚   â”‚   â””â”€â”€ localiza_dw/
â”‚   â”‚       â””â”€â”€ models/
â”‚   â”‚          â”œâ”€â”€ marts/
â”‚   â”‚          â””â”€â”€ staging/
â”‚   â””â”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---
