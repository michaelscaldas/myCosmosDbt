[2025-02-05T13:30:15.701+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T13:30:15.720+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed manual__2025-02-05T13:29:45+00:00 [queued]>
[2025-02-05T13:30:15.732+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed manual__2025-02-05T13:29:45+00:00 [queued]>
[2025-02-05T13:30:15.733+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T13:30:15.749+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.eventos_vendas_seed> on 2025-02-05 13:29:45+00:00
[2025-02-05T13:30:15.755+0000] {standard_task_runner.py:63} INFO - Started process 4132 to run task
[2025-02-05T13:30:15.759+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.eventos_vendas_seed', 'manual__2025-02-05T13:29:45+00:00', '--job-id', '120', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmpn1y7_wzp']
[2025-02-05T13:30:15.761+0000] {standard_task_runner.py:91} INFO - Job 120: Subtask model_sales.eventos_vendas_seed
[2025-02-05T13:30:15.827+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed manual__2025-02-05T13:29:45+00:00 [running]> on host 98025f4a542d
[2025-02-05T13:30:15.939+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.eventos_vendas_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-05T13:29:45+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-02-05T13:29:45+00:00'
[2025-02-05T13:30:15.941+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T13:30:18.911+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T13:30:18.912+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmpyjigzp8r from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T13:30:18.919+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T13:30:18.928+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T13:30:18.941+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T13:30:18.942+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T13:30:18.944+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": P003,                                 "LIMITE_QUANTIDADE": 500,                                 "DATA_INICIO": 1999-01-01,                                 "DATA_FIM": 2025-02-05}', '--models', 'eventos_vendas', '--project-dir', '/tmp/tmpyjigzp8r', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmpyjigzp8r
[2025-02-05T13:30:18.964+0000] {logging_mixin.py:188} INFO - 13:30:18  Running with dbt=1.6.1
[2025-02-05T13:30:19.121+0000] {logging_mixin.py:188} INFO - 13:30:19  Registered adapter: postgres=1.6.1
[2025-02-05T13:30:19.769+0000] {logging_mixin.py:188} INFO - 13:30:19  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T13:30:19.773+0000] {logging_mixin.py:188} INFO - 13:30:19
[2025-02-05T13:30:19.913+0000] {logging_mixin.py:188} INFO - 13:30:19  Concurrency: 1 threads (target='prod')
[2025-02-05T13:30:19.915+0000] {logging_mixin.py:188} INFO - 13:30:19
[2025-02-05T13:30:19.923+0000] {logging_mixin.py:188} INFO - 13:30:19  1 of 1 START seed file dm_sales.eventos_vendas ................................. [RUN]
[2025-02-05T13:30:20.862+0000] {logging_mixin.py:188} INFO - 13:30:20  1 of 1 OK loaded seed file dm_sales.eventos_vendas ............................. [INSERT 535 in 0.94s]
[2025-02-05T13:30:20.878+0000] {logging_mixin.py:188} INFO - 13:30:20
[2025-02-05T13:30:20.880+0000] {logging_mixin.py:188} INFO - 13:30:20  Finished running 1 seed in 0 hours 0 minutes and 1.10 seconds (1.10s).
[2025-02-05T13:30:20.894+0000] {logging_mixin.py:188} INFO - 13:30:20
[2025-02-05T13:30:20.896+0000] {logging_mixin.py:188} INFO - 13:30:20  Completed successfully
[2025-02-05T13:30:20.897+0000] {logging_mixin.py:188} INFO - 13:30:20
[2025-02-05T13:30:20.898+0000] {logging_mixin.py:188} INFO - 13:30:20  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T13:30:21.695+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T13:30:21.699+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T13:30:21.700+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T13:30:21.701+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T13:30:21.702+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T13:30:21.718+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to None, run_after=None
[2025-02-05T13:30:21.745+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T13:30:21.756+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.eventos_vendas_seed, run_id=manual__2025-02-05T13:29:45+00:00, execution_date=20250205T132945, start_date=20250205T133015, end_date=20250205T133021
[2025-02-05T13:30:21.815+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T13:30:21.843+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-05T13:30:21.845+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
