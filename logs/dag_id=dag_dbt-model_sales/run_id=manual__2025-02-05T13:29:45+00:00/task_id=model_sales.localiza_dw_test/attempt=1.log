[2025-02-05T13:30:53.906+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T13:30:53.930+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.localiza_dw_test manual__2025-02-05T13:29:45+00:00 [queued]>
[2025-02-05T13:30:53.944+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.localiza_dw_test manual__2025-02-05T13:29:45+00:00 [queued]>
[2025-02-05T13:30:53.945+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T13:30:53.967+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtTestLocalOperator): model_sales.localiza_dw_test> on 2025-02-05 13:29:45+00:00
[2025-02-05T13:30:53.975+0000] {standard_task_runner.py:63} INFO - Started process 4210 to run task
[2025-02-05T13:30:53.980+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.localiza_dw_test', 'manual__2025-02-05T13:29:45+00:00', '--job-id', '124', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmpqujtgfsw']
[2025-02-05T13:30:53.993+0000] {standard_task_runner.py:91} INFO - Job 124: Subtask model_sales.localiza_dw_test
[2025-02-05T13:30:54.115+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.localiza_dw_test manual__2025-02-05T13:29:45+00:00 [running]> on host 98025f4a542d
[2025-02-05T13:30:54.274+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.localiza_dw_test' AIRFLOW_CTX_EXECUTION_DATE='2025-02-05T13:29:45+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-02-05T13:29:45+00:00'
[2025-02-05T13:30:54.278+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T13:30:57.774+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T13:30:57.776+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmph8qh_80q from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T13:30:57.785+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T13:30:57.792+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T13:30:57.802+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T13:30:57.804+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T13:30:57.806+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['test', '--select', 'path:seeds path:models/marts/sales', '--vars', '{"PROD": P003,                                 "LIMITE_QUANTIDADE": 500,                                 "DATA_INICIO": 1999-01-01,                                 "DATA_FIM": 2025-02-05}', '--project-dir', '/tmp/tmph8qh_80q', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmph8qh_80q
[2025-02-05T13:30:57.829+0000] {logging_mixin.py:188} INFO - 13:30:57  Running with dbt=1.6.1
[2025-02-05T13:30:57.979+0000] {logging_mixin.py:188} INFO - 13:30:57  Registered adapter: postgres=1.6.1
[2025-02-05T13:30:58.697+0000] {logging_mixin.py:188} INFO - 13:30:58  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T13:30:58.715+0000] {logging_mixin.py:188} INFO - 13:30:58
[2025-02-05T13:30:58.717+0000] {logging_mixin.py:188} INFO - 13:30:58  Nothing to do. Try checking your model configs and model specification args
[2025-02-05T13:30:59.516+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T13:30:59.519+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T13:30:59.519+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T13:30:59.520+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T13:30:59.521+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T13:30:59.536+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to None, run_after=None
[2025-02-05T13:30:59.560+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T13:30:59.570+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.***_test, run_id=manual__2025-02-05T13:29:45+00:00, execution_date=20250205T132945, start_date=20250205T133053, end_date=20250205T133059
[2025-02-05T13:30:59.608+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T13:30:59.625+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-05T13:30:59.628+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
