[2025-02-05T13:40:47.978+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T13:40:47.997+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T13:40:48.008+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T13:40:48.009+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T13:40:48.025+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.dim_produto_seed> on 2025-02-04 04:00:00+00:00
[2025-02-05T13:40:48.029+0000] {standard_task_runner.py:63} INFO - Started process 4380 to run task
[2025-02-05T13:40:48.033+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.dim_produto_seed', 'scheduled__2025-02-04T04:00:00+00:00', '--job-id', '129', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmp9py55e9i']
[2025-02-05T13:40:48.034+0000] {standard_task_runner.py:91} INFO - Job 129: Subtask model_sales.dim_produto_seed
[2025-02-05T13:40:48.104+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [running]> on host 98025f4a542d
[2025-02-05T13:40:48.204+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.dim_produto_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-04T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-04T04:00:00+00:00'
[2025-02-05T13:40:48.206+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T13:40:50.696+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T13:40:50.697+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmpl8miyufz from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T13:40:50.707+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T13:40:50.717+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T13:40:50.727+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T13:40:50.728+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T13:40:50.729+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": P003,                                 "LIMITE_QUANTIDADE": 500,                                 "DATA_INICIO": 1999-01-01,                                 "DATA_FIM": 2025-02-05}', '--models', 'dim_produto', '--project-dir', '/tmp/tmpl8miyufz', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmpl8miyufz
[2025-02-05T13:40:50.748+0000] {logging_mixin.py:188} INFO - 13:40:50  Running with dbt=1.6.1
[2025-02-05T13:40:50.860+0000] {logging_mixin.py:188} INFO - 13:40:50  Registered adapter: postgres=1.6.1
[2025-02-05T13:40:51.320+0000] {logging_mixin.py:188} INFO - 13:40:51  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T13:40:51.324+0000] {logging_mixin.py:188} INFO - 13:40:51
[2025-02-05T13:40:51.418+0000] {logging_mixin.py:188} INFO - 13:40:51  Concurrency: 1 threads (target='prod')
[2025-02-05T13:40:51.419+0000] {logging_mixin.py:188} INFO - 13:40:51
[2025-02-05T13:40:51.424+0000] {logging_mixin.py:188} INFO - 13:40:51  1 of 1 START seed file dm_sales.dim_produto .................................... [RUN]
[2025-02-05T13:40:51.529+0000] {logging_mixin.py:188} INFO - 13:40:51  1 of 1 OK loaded seed file dm_sales.dim_produto ................................ [INSERT 5 in 0.10s]
[2025-02-05T13:40:51.544+0000] {logging_mixin.py:188} INFO - 13:40:51
[2025-02-05T13:40:51.545+0000] {logging_mixin.py:188} INFO - 13:40:51  Finished running 1 seed in 0 hours 0 minutes and 0.22 seconds (0.22s).
[2025-02-05T13:40:51.556+0000] {logging_mixin.py:188} INFO - 13:40:51
[2025-02-05T13:40:51.558+0000] {logging_mixin.py:188} INFO - 13:40:51  Completed successfully
[2025-02-05T13:40:51.559+0000] {logging_mixin.py:188} INFO - 13:40:51
[2025-02-05T13:40:51.560+0000] {logging_mixin.py:188} INFO - 13:40:51  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T13:40:52.325+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T13:40:52.327+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T13:40:52.328+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T13:40:52.328+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T13:40:52.328+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T13:40:52.348+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to 2025-02-05 04:00:00+00:00, run_after=2025-02-06 04:00:00+00:00
[2025-02-05T13:40:52.381+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T13:40:52.390+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.dim_produto_seed, run_id=scheduled__2025-02-04T04:00:00+00:00, execution_date=20250204T040000, start_date=20250205T134047, end_date=20250205T134052
[2025-02-05T13:40:52.413+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T13:40:52.437+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-05T13:40:52.439+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-02-05T14:30:10.282+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T14:30:10.301+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T14:30:10.311+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T14:30:10.312+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T14:30:10.325+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.dim_produto_seed> on 2025-02-04 04:00:00+00:00
[2025-02-05T14:30:10.331+0000] {standard_task_runner.py:63} INFO - Started process 133 to run task
[2025-02-05T14:30:10.334+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.dim_produto_seed', 'scheduled__2025-02-04T04:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmpv8t1j_rq']
[2025-02-05T14:30:10.335+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask model_sales.dim_produto_seed
[2025-02-05T14:30:10.391+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [running]> on host eb17fa5f9c23
[2025-02-05T14:30:10.496+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.dim_produto_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-04T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-04T04:00:00+00:00'
[2025-02-05T14:30:10.498+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T14:30:12.860+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T14:30:12.861+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmpv5jool80 from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T14:30:12.869+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T14:30:12.876+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T14:30:12.885+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T14:30:12.886+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T14:30:12.887+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": P003,                                 "LIMITE_QUANTIDADE": 500,                                 "DATA_INICIO": 1999-01-01,                                 "DATA_FIM": 2025-02-05}', '--models', 'dim_produto', '--project-dir', '/tmp/tmpv5jool80', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmpv5jool80
[2025-02-05T14:30:12.904+0000] {logging_mixin.py:188} INFO - 14:30:12  Running with dbt=1.6.1
[2025-02-05T14:30:13.019+0000] {logging_mixin.py:188} INFO - 14:30:13  Registered adapter: postgres=1.6.1
[2025-02-05T14:30:13.603+0000] {logging_mixin.py:188} INFO - 14:30:13  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T14:30:13.606+0000] {logging_mixin.py:188} INFO - 14:30:13
[2025-02-05T14:30:13.679+0000] {logging_mixin.py:188} INFO - 14:30:13  Concurrency: 1 threads (target='prod')
[2025-02-05T14:30:13.680+0000] {logging_mixin.py:188} INFO - 14:30:13
[2025-02-05T14:30:13.684+0000] {logging_mixin.py:188} INFO - 14:30:13  1 of 1 START seed file dm_sales.dim_produto .................................... [RUN]
[2025-02-05T14:30:13.770+0000] {logging_mixin.py:188} INFO - 14:30:13  1 of 1 OK loaded seed file dm_sales.dim_produto ................................ [INSERT 5 in 0.08s]
[2025-02-05T14:30:13.782+0000] {logging_mixin.py:188} INFO - 14:30:13
[2025-02-05T14:30:13.783+0000] {logging_mixin.py:188} INFO - 14:30:13  Finished running 1 seed in 0 hours 0 minutes and 0.18 seconds (0.18s).
[2025-02-05T14:30:13.791+0000] {logging_mixin.py:188} INFO - 14:30:13
[2025-02-05T14:30:13.793+0000] {logging_mixin.py:188} INFO - 14:30:13  Completed successfully
[2025-02-05T14:30:13.794+0000] {logging_mixin.py:188} INFO - 14:30:13
[2025-02-05T14:30:13.795+0000] {logging_mixin.py:188} INFO - 14:30:13  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T14:30:14.545+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T14:30:14.549+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T14:30:14.549+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T14:30:14.550+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T14:30:14.550+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T14:30:14.569+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to 2025-02-05 04:00:00+00:00, run_after=2025-02-06 04:00:00+00:00
[2025-02-05T14:30:14.602+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T14:30:14.610+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.dim_produto_seed, run_id=scheduled__2025-02-04T04:00:00+00:00, execution_date=20250204T040000, start_date=20250205T143010, end_date=20250205T143014
[2025-02-05T14:30:14.653+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T14:30:14.674+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-05T14:30:14.677+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-02-05T14:55:41.962+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T14:55:41.983+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T14:55:41.993+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T14:55:41.993+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T14:55:42.006+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.dim_produto_seed> on 2025-02-04 04:00:00+00:00
[2025-02-05T14:55:42.011+0000] {standard_task_runner.py:63} INFO - Started process 133 to run task
[2025-02-05T14:55:42.014+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.dim_produto_seed', 'scheduled__2025-02-04T04:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmpieiyxygt']
[2025-02-05T14:55:42.015+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask model_sales.dim_produto_seed
[2025-02-05T14:55:42.081+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [running]> on host 7c7f80fafcb7
[2025-02-05T14:55:42.200+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.dim_produto_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-04T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-04T04:00:00+00:00'
[2025-02-05T14:55:42.204+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T14:55:44.584+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T14:55:44.585+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmppw65o4ur from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T14:55:44.591+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T14:55:44.597+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T14:55:44.605+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T14:55:44.607+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T14:55:44.608+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": P003,                                 "LIMITE_QUANTIDADE": 500,                                 "DATA_INICIO": 1999-01-01,                                 "DATA_FIM": 2025-02-05}', '--models', 'dim_produto', '--project-dir', '/tmp/tmppw65o4ur', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmppw65o4ur
[2025-02-05T14:55:44.624+0000] {logging_mixin.py:188} INFO - 14:55:44  Running with dbt=1.6.1
[2025-02-05T14:55:44.730+0000] {logging_mixin.py:188} INFO - 14:55:44  Registered adapter: postgres=1.6.1
[2025-02-05T14:55:45.199+0000] {logging_mixin.py:188} INFO - 14:55:45  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T14:55:45.202+0000] {logging_mixin.py:188} INFO - 14:55:45
[2025-02-05T14:55:45.279+0000] {logging_mixin.py:188} INFO - 14:55:45  Concurrency: 1 threads (target='prod')
[2025-02-05T14:55:45.280+0000] {logging_mixin.py:188} INFO - 14:55:45
[2025-02-05T14:55:45.284+0000] {logging_mixin.py:188} INFO - 14:55:45  1 of 1 START seed file dm_sales.dim_produto .................................... [RUN]
[2025-02-05T14:55:45.372+0000] {logging_mixin.py:188} INFO - 14:55:45  1 of 1 OK loaded seed file dm_sales.dim_produto ................................ [INSERT 5 in 0.09s]
[2025-02-05T14:55:45.383+0000] {logging_mixin.py:188} INFO - 14:55:45
[2025-02-05T14:55:45.385+0000] {logging_mixin.py:188} INFO - 14:55:45  Finished running 1 seed in 0 hours 0 minutes and 0.18 seconds (0.18s).
[2025-02-05T14:55:45.393+0000] {logging_mixin.py:188} INFO - 14:55:45
[2025-02-05T14:55:45.394+0000] {logging_mixin.py:188} INFO - 14:55:45  Completed successfully
[2025-02-05T14:55:45.395+0000] {logging_mixin.py:188} INFO - 14:55:45
[2025-02-05T14:55:45.396+0000] {logging_mixin.py:188} INFO - 14:55:45  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T14:55:47.052+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T14:55:47.055+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T14:55:47.056+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T14:55:47.056+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T14:55:47.057+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T14:55:47.073+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to 2025-02-05 04:00:00+00:00, run_after=2025-02-06 04:00:00+00:00
[2025-02-05T14:55:47.092+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T14:55:47.099+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.dim_produto_seed, run_id=scheduled__2025-02-04T04:00:00+00:00, execution_date=20250204T040000, start_date=20250205T145541, end_date=20250205T145547
[2025-02-05T14:55:47.142+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T14:55:47.158+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-05T14:55:47.160+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-02-05T15:07:12.252+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T15:07:12.273+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T15:07:12.286+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T15:07:12.287+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T15:07:12.306+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.dim_produto_seed> on 2025-02-04 04:00:00+00:00
[2025-02-05T15:07:12.312+0000] {standard_task_runner.py:63} INFO - Started process 132 to run task
[2025-02-05T15:07:12.317+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.dim_produto_seed', 'scheduled__2025-02-04T04:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmp7l79pzgn']
[2025-02-05T15:07:12.318+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask model_sales.dim_produto_seed
[2025-02-05T15:07:12.397+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [running]> on host 5c897c3a2254
[2025-02-05T15:07:12.506+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.dim_produto_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-04T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-04T04:00:00+00:00'
[2025-02-05T15:07:12.509+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T15:07:14.839+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T15:07:14.841+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmpqhjis2gx from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T15:07:14.847+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T15:07:14.855+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T15:07:14.863+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T15:07:14.865+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T15:07:14.865+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": "P003", "LIMITE_QUANTIDADE": "500", "DATA_INICIO": "1999-01-01", "DATA_FIM": "2025-02-05"}', '--models', 'dim_produto', '--project-dir', '/tmp/tmpqhjis2gx', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmpqhjis2gx
[2025-02-05T15:07:14.881+0000] {logging_mixin.py:188} INFO - 15:07:14  Running with dbt=1.6.1
[2025-02-05T15:07:14.998+0000] {logging_mixin.py:188} INFO - 15:07:14  Registered adapter: postgres=1.6.1
[2025-02-05T15:07:15.540+0000] {logging_mixin.py:188} INFO - 15:07:15  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T15:07:15.542+0000] {logging_mixin.py:188} INFO - 15:07:15
[2025-02-05T15:07:15.624+0000] {logging_mixin.py:188} INFO - 15:07:15  Concurrency: 1 threads (target='prod')
[2025-02-05T15:07:15.625+0000] {logging_mixin.py:188} INFO - 15:07:15
[2025-02-05T15:07:15.629+0000] {logging_mixin.py:188} INFO - 15:07:15  1 of 1 START seed file dm_sales.dim_produto .................................... [RUN]
[2025-02-05T15:07:15.715+0000] {logging_mixin.py:188} INFO - 15:07:15  1 of 1 OK loaded seed file dm_sales.dim_produto ................................ [INSERT 5 in 0.08s]
[2025-02-05T15:07:15.727+0000] {logging_mixin.py:188} INFO - 15:07:15
[2025-02-05T15:07:15.728+0000] {logging_mixin.py:188} INFO - 15:07:15  Finished running 1 seed in 0 hours 0 minutes and 0.18 seconds (0.18s).
[2025-02-05T15:07:15.737+0000] {logging_mixin.py:188} INFO - 15:07:15
[2025-02-05T15:07:15.738+0000] {logging_mixin.py:188} INFO - 15:07:15  Completed successfully
[2025-02-05T15:07:15.739+0000] {logging_mixin.py:188} INFO - 15:07:15
[2025-02-05T15:07:15.740+0000] {logging_mixin.py:188} INFO - 15:07:15  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T15:07:16.493+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T15:07:16.502+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T15:07:16.503+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T15:07:16.504+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T15:07:16.505+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T15:07:16.524+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to 2025-02-05 04:00:00+00:00, run_after=2025-02-06 04:00:00+00:00
[2025-02-05T15:07:16.544+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T15:07:16.552+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.dim_produto_seed, run_id=scheduled__2025-02-04T04:00:00+00:00, execution_date=20250204T040000, start_date=20250205T150712, end_date=20250205T150716
[2025-02-05T15:07:16.585+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T15:07:16.604+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-05T15:07:16.606+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-02-05T16:45:09.264+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T16:45:09.279+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T16:45:09.286+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T16:45:09.287+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T16:45:09.300+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.dim_produto_seed> on 2025-02-04 04:00:00+00:00
[2025-02-05T16:45:09.305+0000] {standard_task_runner.py:63} INFO - Started process 130 to run task
[2025-02-05T16:45:09.309+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.dim_produto_seed', 'scheduled__2025-02-04T04:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmp4qpj2oxs']
[2025-02-05T16:45:09.310+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask model_sales.dim_produto_seed
[2025-02-05T16:45:09.363+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.dim_produto_seed scheduled__2025-02-04T04:00:00+00:00 [running]> on host 584eb3626689
[2025-02-05T16:45:09.444+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.dim_produto_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-04T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-04T04:00:00+00:00'
[2025-02-05T16:45:09.447+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T16:45:10.106+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T16:45:10.109+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmpjiz2spum from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T16:45:10.117+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T16:45:10.123+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T16:45:10.130+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T16:45:10.132+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T16:45:10.132+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": "P003", "LIMITE_QUANTIDADE": "500", "DATA_INICIO": "1999-01-01", "DATA_FIM": "2025-02-05"}', '--models', 'dim_produto', '--project-dir', '/tmp/tmpjiz2spum', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmpjiz2spum
[2025-02-05T16:45:10.150+0000] {logging_mixin.py:188} INFO - 16:45:10  Running with dbt=1.6.1
[2025-02-05T16:45:10.258+0000] {logging_mixin.py:188} INFO - 16:45:10  Registered adapter: postgres=1.6.1
[2025-02-05T16:45:10.844+0000] {logging_mixin.py:188} INFO - 16:45:10  Found 5 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T16:45:10.846+0000] {logging_mixin.py:188} INFO - 16:45:10
[2025-02-05T16:45:10.921+0000] {logging_mixin.py:188} INFO - 16:45:10  Concurrency: 1 threads (target='prod')
[2025-02-05T16:45:10.922+0000] {logging_mixin.py:188} INFO - 16:45:10
[2025-02-05T16:45:10.925+0000] {logging_mixin.py:188} INFO - 16:45:10  1 of 1 START seed file dm_sales.dim_produto .................................... [RUN]
[2025-02-05T16:45:11.010+0000] {logging_mixin.py:188} INFO - 16:45:11  1 of 1 OK loaded seed file dm_sales.dim_produto ................................ [INSERT 5 in 0.08s]
[2025-02-05T16:45:11.021+0000] {logging_mixin.py:188} INFO - 16:45:11
[2025-02-05T16:45:11.022+0000] {logging_mixin.py:188} INFO - 16:45:11  Finished running 1 seed in 0 hours 0 minutes and 0.17 seconds (0.17s).
[2025-02-05T16:45:11.031+0000] {logging_mixin.py:188} INFO - 16:45:11
[2025-02-05T16:45:11.032+0000] {logging_mixin.py:188} INFO - 16:45:11  Completed successfully
[2025-02-05T16:45:11.033+0000] {logging_mixin.py:188} INFO - 16:45:11
[2025-02-05T16:45:11.034+0000] {logging_mixin.py:188} INFO - 16:45:11  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T16:45:11.899+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T16:45:11.901+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T16:45:11.901+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T16:45:11.902+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T16:45:11.902+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T16:45:11.922+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to 2025-02-05 04:00:00+00:00, run_after=2025-02-06 04:00:00+00:00
[2025-02-05T16:45:11.951+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T16:45:11.956+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.dim_produto_seed, run_id=scheduled__2025-02-04T04:00:00+00:00, execution_date=20250204T040000, start_date=20250205T164509, end_date=20250205T164511
[2025-02-05T16:45:12.011+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T16:45:12.029+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-05T16:45:12.031+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
