[2025-02-05T13:40:30.059+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T13:40:30.081+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T13:40:30.091+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T13:40:30.092+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T13:40:30.106+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.eventos_vendas_seed> on 2025-02-04 04:00:00+00:00
[2025-02-05T13:40:30.112+0000] {standard_task_runner.py:63} INFO - Started process 4334 to run task
[2025-02-05T13:40:30.115+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.eventos_vendas_seed', 'scheduled__2025-02-04T04:00:00+00:00', '--job-id', '127', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmp6u9jhkv4']
[2025-02-05T13:40:30.116+0000] {standard_task_runner.py:91} INFO - Job 127: Subtask model_sales.eventos_vendas_seed
[2025-02-05T13:40:30.180+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [running]> on host 98025f4a542d
[2025-02-05T13:40:30.282+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.eventos_vendas_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-04T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-04T04:00:00+00:00'
[2025-02-05T13:40:30.284+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T13:40:33.232+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T13:40:33.234+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmpsfhmytt6 from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T13:40:33.244+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T13:40:33.251+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T13:40:33.264+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T13:40:33.266+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T13:40:33.267+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": P003,                                 "LIMITE_QUANTIDADE": 500,                                 "DATA_INICIO": 1999-01-01,                                 "DATA_FIM": 2025-02-05}', '--models', 'eventos_vendas', '--project-dir', '/tmp/tmpsfhmytt6', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmpsfhmytt6
[2025-02-05T13:40:33.290+0000] {logging_mixin.py:188} INFO - 13:40:33  Running with dbt=1.6.1
[2025-02-05T13:40:33.426+0000] {logging_mixin.py:188} INFO - 13:40:33  Registered adapter: postgres=1.6.1
[2025-02-05T13:40:34.112+0000] {logging_mixin.py:188} INFO - 13:40:34  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T13:40:34.114+0000] {logging_mixin.py:188} INFO - 13:40:34
[2025-02-05T13:40:34.202+0000] {logging_mixin.py:188} INFO - 13:40:34  Concurrency: 1 threads (target='prod')
[2025-02-05T13:40:34.203+0000] {logging_mixin.py:188} INFO - 13:40:34
[2025-02-05T13:40:34.208+0000] {logging_mixin.py:188} INFO - 13:40:34  1 of 1 START seed file dm_sales.eventos_vendas ................................. [RUN]
[2025-02-05T13:40:34.851+0000] {logging_mixin.py:188} INFO - 13:40:34  1 of 1 OK loaded seed file dm_sales.eventos_vendas ............................. [INSERT 535 in 0.64s]
[2025-02-05T13:40:34.865+0000] {logging_mixin.py:188} INFO - 13:40:34
[2025-02-05T13:40:34.866+0000] {logging_mixin.py:188} INFO - 13:40:34  Finished running 1 seed in 0 hours 0 minutes and 0.75 seconds (0.75s).
[2025-02-05T13:40:34.876+0000] {logging_mixin.py:188} INFO - 13:40:34
[2025-02-05T13:40:34.877+0000] {logging_mixin.py:188} INFO - 13:40:34  Completed successfully
[2025-02-05T13:40:34.878+0000] {logging_mixin.py:188} INFO - 13:40:34
[2025-02-05T13:40:34.880+0000] {logging_mixin.py:188} INFO - 13:40:34  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T13:40:35.930+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T13:40:35.933+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T13:40:35.934+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T13:40:35.935+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T13:40:35.935+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T13:40:35.956+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to 2025-02-05 04:00:00+00:00, run_after=2025-02-06 04:00:00+00:00
[2025-02-05T13:40:35.986+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T13:40:35.994+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.eventos_vendas_seed, run_id=scheduled__2025-02-04T04:00:00+00:00, execution_date=20250204T040000, start_date=20250205T134030, end_date=20250205T134035
[2025-02-05T13:40:36.045+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T13:40:36.071+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-05T13:40:36.075+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-02-05T14:29:52.607+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T14:29:52.623+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T14:29:52.633+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T14:29:52.634+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T14:29:52.645+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.eventos_vendas_seed> on 2025-02-04 04:00:00+00:00
[2025-02-05T14:29:52.650+0000] {standard_task_runner.py:63} INFO - Started process 90 to run task
[2025-02-05T14:29:52.654+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.eventos_vendas_seed', 'scheduled__2025-02-04T04:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmpqka_vi95']
[2025-02-05T14:29:52.655+0000] {standard_task_runner.py:91} INFO - Job 4: Subtask model_sales.eventos_vendas_seed
[2025-02-05T14:29:52.716+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [running]> on host eb17fa5f9c23
[2025-02-05T14:29:52.797+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.eventos_vendas_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-04T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-04T04:00:00+00:00'
[2025-02-05T14:29:52.799+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T14:29:55.604+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T14:29:55.606+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmp0b53m2zm from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T14:29:55.614+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T14:29:55.622+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T14:29:55.638+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T14:29:55.639+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T14:29:55.641+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": P003,                                 "LIMITE_QUANTIDADE": 500,                                 "DATA_INICIO": 1999-01-01,                                 "DATA_FIM": 2025-02-05}', '--models', 'eventos_vendas', '--project-dir', '/tmp/tmp0b53m2zm', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmp0b53m2zm
[2025-02-05T14:29:55.664+0000] {logging_mixin.py:188} INFO - 14:29:55  Running with dbt=1.6.1
[2025-02-05T14:29:55.810+0000] {logging_mixin.py:188} INFO - 14:29:55  Registered adapter: postgres=1.6.1
[2025-02-05T14:29:56.601+0000] {logging_mixin.py:188} INFO - 14:29:56  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T14:29:56.605+0000] {logging_mixin.py:188} INFO - 14:29:56
[2025-02-05T14:29:56.711+0000] {logging_mixin.py:188} INFO - 14:29:56  Concurrency: 1 threads (target='prod')
[2025-02-05T14:29:56.713+0000] {logging_mixin.py:188} INFO - 14:29:56
[2025-02-05T14:29:56.718+0000] {logging_mixin.py:188} INFO - 14:29:56  1 of 1 START seed file dm_sales.eventos_vendas ................................. [RUN]
[2025-02-05T14:29:57.613+0000] {logging_mixin.py:188} INFO - 14:29:57  1 of 1 OK loaded seed file dm_sales.eventos_vendas ............................. [INSERT 535 in 0.89s]
[2025-02-05T14:29:57.637+0000] {logging_mixin.py:188} INFO - 14:29:57
[2025-02-05T14:29:57.638+0000] {logging_mixin.py:188} INFO - 14:29:57  Finished running 1 seed in 0 hours 0 minutes and 1.03 seconds (1.03s).
[2025-02-05T14:29:57.650+0000] {logging_mixin.py:188} INFO - 14:29:57
[2025-02-05T14:29:57.652+0000] {logging_mixin.py:188} INFO - 14:29:57  Completed successfully
[2025-02-05T14:29:57.653+0000] {logging_mixin.py:188} INFO - 14:29:57
[2025-02-05T14:29:57.655+0000] {logging_mixin.py:188} INFO - 14:29:57  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T14:29:58.430+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T14:29:58.433+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T14:29:58.434+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T14:29:58.434+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T14:29:58.435+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T14:29:58.463+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to 2025-02-05 04:00:00+00:00, run_after=2025-02-06 04:00:00+00:00
[2025-02-05T14:29:58.490+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T14:29:58.502+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.eventos_vendas_seed, run_id=scheduled__2025-02-04T04:00:00+00:00, execution_date=20250204T040000, start_date=20250205T142952, end_date=20250205T142958
[2025-02-05T14:29:58.528+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T14:29:58.559+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-05T14:29:58.562+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-02-05T14:55:25.903+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T14:55:25.918+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T14:55:25.926+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T14:55:25.927+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T14:55:25.936+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.eventos_vendas_seed> on 2025-02-04 04:00:00+00:00
[2025-02-05T14:55:25.941+0000] {standard_task_runner.py:63} INFO - Started process 90 to run task
[2025-02-05T14:55:25.943+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.eventos_vendas_seed', 'scheduled__2025-02-04T04:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmp4ccx1147']
[2025-02-05T14:55:25.945+0000] {standard_task_runner.py:91} INFO - Job 4: Subtask model_sales.eventos_vendas_seed
[2025-02-05T14:55:25.997+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [running]> on host 7c7f80fafcb7
[2025-02-05T14:55:26.067+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.eventos_vendas_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-04T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-04T04:00:00+00:00'
[2025-02-05T14:55:26.069+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T14:55:28.066+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T14:55:28.067+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmpqvhvd3kh from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T14:55:28.074+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T14:55:28.079+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T14:55:28.088+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T14:55:28.089+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T14:55:28.090+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": P003,                                 "LIMITE_QUANTIDADE": 500,                                 "DATA_INICIO": 1999-01-01,                                 "DATA_FIM": 2025-02-05}', '--models', 'eventos_vendas', '--project-dir', '/tmp/tmpqvhvd3kh', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmpqvhvd3kh
[2025-02-05T14:55:28.110+0000] {logging_mixin.py:188} INFO - 14:55:28  Running with dbt=1.6.1
[2025-02-05T14:55:28.213+0000] {logging_mixin.py:188} INFO - 14:55:28  Registered adapter: postgres=1.6.1
[2025-02-05T14:55:28.763+0000] {logging_mixin.py:188} INFO - 14:55:28  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T14:55:28.766+0000] {logging_mixin.py:188} INFO - 14:55:28
[2025-02-05T14:55:28.841+0000] {logging_mixin.py:188} INFO - 14:55:28  Concurrency: 1 threads (target='prod')
[2025-02-05T14:55:28.843+0000] {logging_mixin.py:188} INFO - 14:55:28
[2025-02-05T14:55:28.848+0000] {logging_mixin.py:188} INFO - 14:55:28  1 of 1 START seed file dm_sales.eventos_vendas ................................. [RUN]
[2025-02-05T14:55:29.508+0000] {logging_mixin.py:188} INFO - 14:55:29  1 of 1 OK loaded seed file dm_sales.eventos_vendas ............................. [INSERT 535 in 0.66s]
[2025-02-05T14:55:29.522+0000] {logging_mixin.py:188} INFO - 14:55:29
[2025-02-05T14:55:29.523+0000] {logging_mixin.py:188} INFO - 14:55:29  Finished running 1 seed in 0 hours 0 minutes and 0.75 seconds (0.75s).
[2025-02-05T14:55:29.532+0000] {logging_mixin.py:188} INFO - 14:55:29
[2025-02-05T14:55:29.533+0000] {logging_mixin.py:188} INFO - 14:55:29  Completed successfully
[2025-02-05T14:55:29.534+0000] {logging_mixin.py:188} INFO - 14:55:29
[2025-02-05T14:55:29.536+0000] {logging_mixin.py:188} INFO - 14:55:29  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T14:55:30.283+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T14:55:30.286+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T14:55:30.286+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T14:55:30.286+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T14:55:30.290+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T14:55:30.306+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to 2025-02-05 04:00:00+00:00, run_after=2025-02-06 04:00:00+00:00
[2025-02-05T14:55:30.340+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T14:55:30.347+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.eventos_vendas_seed, run_id=scheduled__2025-02-04T04:00:00+00:00, execution_date=20250204T040000, start_date=20250205T145525, end_date=20250205T145530
[2025-02-05T14:55:30.400+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T14:55:30.420+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-05T14:55:30.422+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-02-05T15:06:54.180+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T15:06:54.196+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T15:06:54.204+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T15:06:54.205+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T15:06:54.215+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.eventos_vendas_seed> on 2025-02-04 04:00:00+00:00
[2025-02-05T15:06:54.220+0000] {standard_task_runner.py:63} INFO - Started process 90 to run task
[2025-02-05T15:06:54.223+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.eventos_vendas_seed', 'scheduled__2025-02-04T04:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmpwls533jb']
[2025-02-05T15:06:54.224+0000] {standard_task_runner.py:91} INFO - Job 4: Subtask model_sales.eventos_vendas_seed
[2025-02-05T15:06:54.272+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [running]> on host 5c897c3a2254
[2025-02-05T15:06:54.347+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.eventos_vendas_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-04T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-04T04:00:00+00:00'
[2025-02-05T15:06:54.349+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T15:06:54.873+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T15:06:54.875+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmpfg7jvgec from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T15:06:54.885+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T15:06:54.890+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T15:06:54.899+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T15:06:54.901+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T15:06:54.902+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": "P003", "LIMITE_QUANTIDADE": "500", "DATA_INICIO": "1999-01-01", "DATA_FIM": "2025-02-05"}', '--models', 'eventos_vendas', '--project-dir', '/tmp/tmpfg7jvgec', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmpfg7jvgec
[2025-02-05T15:06:54.922+0000] {logging_mixin.py:188} INFO - 15:06:54  Running with dbt=1.6.1
[2025-02-05T15:06:55.039+0000] {logging_mixin.py:188} INFO - 15:06:55  Registered adapter: postgres=1.6.1
[2025-02-05T15:06:55.585+0000] {logging_mixin.py:188} INFO - 15:06:55  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T15:06:55.588+0000] {logging_mixin.py:188} INFO - 15:06:55
[2025-02-05T15:06:55.660+0000] {logging_mixin.py:188} INFO - 15:06:55  Concurrency: 1 threads (target='prod')
[2025-02-05T15:06:55.661+0000] {logging_mixin.py:188} INFO - 15:06:55
[2025-02-05T15:06:55.665+0000] {logging_mixin.py:188} INFO - 15:06:55  1 of 1 START seed file dm_sales.eventos_vendas ................................. [RUN]
[2025-02-05T15:06:56.286+0000] {logging_mixin.py:188} INFO - 15:06:56  1 of 1 OK loaded seed file dm_sales.eventos_vendas ............................. [INSERT 535 in 0.62s]
[2025-02-05T15:06:56.299+0000] {logging_mixin.py:188} INFO - 15:06:56
[2025-02-05T15:06:56.300+0000] {logging_mixin.py:188} INFO - 15:06:56  Finished running 1 seed in 0 hours 0 minutes and 0.71 seconds (0.71s).
[2025-02-05T15:06:56.309+0000] {logging_mixin.py:188} INFO - 15:06:56
[2025-02-05T15:06:56.310+0000] {logging_mixin.py:188} INFO - 15:06:56  Completed successfully
[2025-02-05T15:06:56.311+0000] {logging_mixin.py:188} INFO - 15:06:56
[2025-02-05T15:06:56.312+0000] {logging_mixin.py:188} INFO - 15:06:56  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T15:06:57.056+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T15:06:57.058+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T15:06:57.059+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T15:06:57.059+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T15:06:57.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T15:06:57.077+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to 2025-02-05 04:00:00+00:00, run_after=2025-02-06 04:00:00+00:00
[2025-02-05T15:06:57.110+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T15:06:57.118+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.eventos_vendas_seed, run_id=scheduled__2025-02-04T04:00:00+00:00, execution_date=20250204T040000, start_date=20250205T150654, end_date=20250205T150657
[2025-02-05T15:06:57.142+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T15:06:57.174+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-05T15:06:57.176+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-02-05T16:44:44.618+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T16:44:44.635+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T16:44:44.643+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [queued]>
[2025-02-05T16:44:44.643+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T16:44:44.654+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtSeedLocalOperator): model_sales.eventos_vendas_seed> on 2025-02-04 04:00:00+00:00
[2025-02-05T16:44:44.658+0000] {standard_task_runner.py:63} INFO - Started process 56 to run task
[2025-02-05T16:44:44.663+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.eventos_vendas_seed', 'scheduled__2025-02-04T04:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmpxf1oo7nl']
[2025-02-05T16:44:44.665+0000] {standard_task_runner.py:91} INFO - Job 3: Subtask model_sales.eventos_vendas_seed
[2025-02-05T16:44:44.712+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.eventos_vendas_seed scheduled__2025-02-04T04:00:00+00:00 [running]> on host 584eb3626689
[2025-02-05T16:44:44.784+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.eventos_vendas_seed' AIRFLOW_CTX_EXECUTION_DATE='2025-02-04T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-04T04:00:00+00:00'
[2025-02-05T16:44:44.786+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T16:44:47.051+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T16:44:47.052+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmp50cgoib9 from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T16:44:47.061+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /usr/local/airflow/dags/dbt/localiza_dw/target/partial_parse.msgpack
[2025-02-05T16:44:47.101+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T16:44:47.110+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T16:44:47.111+0000] {base.py:244} INFO - Using real values for profile ***
[2025-02-05T16:44:47.114+0000] {config.py:335} INFO - Profile not found in cache storing and using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T16:44:47.115+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['seed', '--vars', '{"PROD": "P003", "LIMITE_QUANTIDADE": "500", "DATA_INICIO": "1999-01-01", "DATA_FIM": "2025-02-05"}', '--models', 'eventos_vendas', '--project-dir', '/tmp/tmp50cgoib9', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmp50cgoib9
[2025-02-05T16:44:47.136+0000] {logging_mixin.py:188} INFO - 16:44:47  Running with dbt=1.6.1
[2025-02-05T16:44:47.249+0000] {logging_mixin.py:188} INFO - 16:44:47  Registered adapter: postgres=1.6.1
[2025-02-05T16:44:47.272+0000] {logging_mixin.py:188} INFO - 16:44:47  Unable to do partial parsing because of a version mismatch
[2025-02-05T16:44:48.501+0000] {logging_mixin.py:188} INFO - 16:44:48  Found 5 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T16:44:48.505+0000] {logging_mixin.py:188} INFO - 16:44:48
[2025-02-05T16:44:48.612+0000] {logging_mixin.py:188} INFO - 16:44:48  Concurrency: 1 threads (target='prod')
[2025-02-05T16:44:48.613+0000] {logging_mixin.py:188} INFO - 16:44:48
[2025-02-05T16:44:48.617+0000] {logging_mixin.py:188} INFO - 16:44:48  1 of 1 START seed file dm_sales.eventos_vendas ................................. [RUN]
[2025-02-05T16:44:49.292+0000] {logging_mixin.py:188} INFO - 16:44:49  1 of 1 OK loaded seed file dm_sales.eventos_vendas ............................. [INSERT 535 in 0.67s]
[2025-02-05T16:44:49.305+0000] {logging_mixin.py:188} INFO - 16:44:49
[2025-02-05T16:44:49.307+0000] {logging_mixin.py:188} INFO - 16:44:49  Finished running 1 seed in 0 hours 0 minutes and 0.80 seconds (0.80s).
[2025-02-05T16:44:49.318+0000] {logging_mixin.py:188} INFO - 16:44:49
[2025-02-05T16:44:49.319+0000] {logging_mixin.py:188} INFO - 16:44:49  Completed successfully
[2025-02-05T16:44:49.321+0000] {logging_mixin.py:188} INFO - 16:44:49
[2025-02-05T16:44:49.322+0000] {logging_mixin.py:188} INFO - 16:44:49  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[2025-02-05T16:44:50.079+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T16:44:50.082+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T16:44:50.083+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T16:44:50.084+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T16:44:50.085+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T16:44:50.101+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to 2025-02-05 04:00:00+00:00, run_after=2025-02-06 04:00:00+00:00
[2025-02-05T16:44:50.132+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T16:44:50.139+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.eventos_vendas_seed, run_id=scheduled__2025-02-04T04:00:00+00:00, execution_date=20250204T040000, start_date=20250205T164444, end_date=20250205T164450
[2025-02-05T16:44:50.162+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T16:44:50.182+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-05T16:44:50.185+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
