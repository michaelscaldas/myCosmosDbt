[2025-02-05T13:26:00.389+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-05T13:26:00.412+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.localiza_dw_test manual__2025-02-05T13:24:50+00:00 [queued]>
[2025-02-05T13:26:00.426+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_dbt-model_sales.model_sales.localiza_dw_test manual__2025-02-05T13:24:50+00:00 [queued]>
[2025-02-05T13:26:00.427+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-05T13:26:00.446+0000] {taskinstance.py:2330} INFO - Executing <Task(DbtTestLocalOperator): model_sales.localiza_dw_test> on 2025-02-05 13:24:50+00:00
[2025-02-05T13:26:00.454+0000] {standard_task_runner.py:63} INFO - Started process 4045 to run task
[2025-02-05T13:26:00.457+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_dbt-model_sales', 'model_sales.localiza_dw_test', 'manual__2025-02-05T13:24:50+00:00', '--job-id', '118', '--raw', '--subdir', 'DAGS_FOLDER/dag_dbt-model_sales.py', '--cfg-path', '/tmp/tmpt7i17e1l']
[2025-02-05T13:26:00.459+0000] {standard_task_runner.py:91} INFO - Job 118: Subtask model_sales.localiza_dw_test
[2025-02-05T13:26:00.541+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_dbt-model_sales.model_sales.localiza_dw_test manual__2025-02-05T13:24:50+00:00 [running]> on host 98025f4a542d
[2025-02-05T13:26:00.661+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_dbt-model_sales' AIRFLOW_CTX_TASK_ID='model_sales.localiza_dw_test' AIRFLOW_CTX_EXECUTION_DATE='2025-02-05T13:24:50+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-02-05T13:24:50+00:00'
[2025-02-05T13:26:00.664+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-05T13:26:02.079+0000] {local.py:220} INFO - dbtRunner is available. Using dbtRunner for invoking dbt.
[2025-02-05T13:26:02.081+0000] {local.py:436} INFO - Cloning project to writable temp directory /tmp/tmp54xbmfwc from /usr/local/airflow/dags/dbt/localiza_dw
[2025-02-05T13:26:02.092+0000] {local.py:447} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/dag_dbt-model_sales__model_sales/target/partial_parse.msgpack
[2025-02-05T13:26:02.104+0000] {config.py:348} INFO - Profile caching is enable.
[2025-02-05T13:26:02.122+0000] {base.py:84} INFO - Using connection ID '***' for task execution.
[2025-02-05T13:26:02.125+0000] {config.py:328} INFO - Profile found in cache using profile: /tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf/profiles.yml.
[2025-02-05T13:26:02.127+0000] {local.py:408} INFO - Trying to run dbtRunner with:
 ['test', '--select', 'path:seeds path:models/marts/sales', '--vars', '{"PROD": P003,                                 "LIMITE_QUANTIDADE": 500,                                 "DATA_INICIO": 1999-01-01,                                 "DATA_FIM": 2025-02-05}', '--project-dir', '/tmp/tmp54xbmfwc', '--profiles-dir', '/tmp/cosmos/profile/47873256e3df2d6067f929148b3671caee72f33396318ef25aae33418849eddf', '--profile', '***', '--target', 'prod']
 in /tmp/tmp54xbmfwc
[2025-02-05T13:26:02.156+0000] {logging_mixin.py:188} INFO - 13:26:02  Running with dbt=1.6.1
[2025-02-05T13:26:02.311+0000] {logging_mixin.py:188} INFO - 13:26:02  Registered adapter: postgres=1.6.1
[2025-02-05T13:26:03.057+0000] {logging_mixin.py:188} INFO - 13:26:03  Found 4 models, 1 snapshot, 4 seeds, 5 tests, 3 sources, 0 exposures, 0 metrics, 349 macros, 0 groups, 0 semantic models
[2025-02-05T13:26:03.070+0000] {logging_mixin.py:188} INFO - 13:26:03
[2025-02-05T13:26:03.072+0000] {logging_mixin.py:188} INFO - 13:26:03  Nothing to do. Try checking your model configs and model specification args
[2025-02-05T13:26:04.092+0000] {local.py:138} WARNING - Artifact schema version: https://schemas.getdbt.com/dbt/manifest/v10.json is above dbt-ol supported version 7. This might cause errors.
[2025-02-05T13:26:04.096+0000] {local.py:494} INFO - Inlets: []
[2025-02-05T13:26:04.096+0000] {local.py:495} INFO - Outlets: []
[2025-02-05T13:26:04.097+0000] {local.py:595} INFO - Assigning inlets/outlets without DatasetAlias
[2025-02-05T13:26:04.098+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-02-05T13:26:04.112+0000] {dag.py:3954} INFO - Setting next_dagrun for dag_dbt-model_sales to None, run_after=None
[2025-02-05T13:26:04.148+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-05T13:26:04.158+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_dbt-model_sales, task_id=model_sales.***_test, run_id=manual__2025-02-05T13:24:50+00:00, execution_date=20250205T132450, start_date=20250205T132600, end_date=20250205T132604
[2025-02-05T13:26:05.321+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-02-05T13:26:05.339+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-05T13:26:05.341+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
